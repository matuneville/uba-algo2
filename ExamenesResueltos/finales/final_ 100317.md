# Final de Feuerstein, fecha 10/03/17

## Ejercicio 1

### Consigna

Responder Verdadero o Falso. Justificar.

- a) Lo que hace que una operación sea un observador básico es que deba escribirse en base a los generadores.
- b) Si una operación rompe la congruencia debe ser transformada en observador básico.
- c) Dos instancias del mismo TAD pueden ser observacionalmente iguales y aun así ser distinguibles por una operación.
- d) Si un enunciado dice "Siempre que vale A sucede inmediatamente B y B no puede suceder de ninguna otra manera" y la correspondiente axiomatización incluye las operaciones A y B entonces el TAD está mal escrito.

### Resolución

a) Falso. Esto es solo una propiedad esencial de los observadores básicos en su aximatización, pero no es eso lo que los define. Si no, una operación que no es un observador también podría axiomatizarse en función de los generadores, y no por eso sería un observador.  
b) Verdadero.   
c) Falso. Esto solo sería posible si hay incongruencia en la especificación del TAD. Por definición, dos instancias de TADs son observacionalmente iguales si, para todo observador, coinciden sus salidas al tener las mismas entradas. Y como las otras operaciones se axiomatizan en base a los observadores, no tendría sentido matemático que tuvieran diferente resultado.  
d) Verdadero. Es comportamiento automático, por lo que la axiomatización del evento B no se debe realizar.


## Ejercicio 2

### Consigna

En cada uno de los siguientes escenarios, indique qué método de ordenamiento de los estudiados en clase utilizaría y porque.

- a) Se tiene un arreglo de naturales A[1..n] y se desea ordenarlos (de mayor a menor) solamente sí la suma de los k elementos más grandes es menor que X. Se desea realizar ésta tarea de forma eficiente, dandola por terminada lo antes posible si la condición no se cumple. (La verificación forma parte de la tarea, no se debe verificar la condición antes de empezar a ordenar)
  
- b) Se tiene un arreglo redimensionable de naturales A[1..n] y se desea ordenarlos. Sin embargo, durante el proceso de ordenamiento es posible que se agreguen nuevos elementos al final del arreglo.

### Resolución

a) Primero, guardo en otro arreglo B el arreglo A pero heapifycado (con el algoritmo de Floyd). Esto me llevará O(n). Luego veo si la suma de los K primeros elementos son mayores que X, que cuesta O(K log n). Si es así, entonces hago un heapsort de B sobre A, es decir, desencolo n veces del max-heap y formo el nuevo A, que cuesta O(n log n). Si no, devuelvo A sin modificar, que costaría (n + K log n).  

b) Podemos utilizar un insertion sort y sería la mejor opción. 


## Ejercicio 3

### Consigna

Decir si es Verdadero o Falso (justificar o dar contraejemplo)

Sea S el arreglo de claves representado por como un max-heap.

a) Sean S[i] y S[j] claves del heap / i < j y S[i] < S[j] → el arreglo obtenido al intercambiar S[i] y S[j] sigue siendo max-heap.  
b) Sean S[i] y S[j] claves del heap / i < j y S[i] > S[j] → el arreglo obtenido al intercambiar S[i] y S[j] sigue siendo max-heap.

### Resuelto en [este final](/ExamenesResueltos/finales/final_101215.md)

## Ejercicio 4

a) ¿Cuántos caracteres DISTINTOS tiene que tener un texto como mínimo para que alguno de ellos reciba un código de longitud k en una codificación de Huffman (con k>1)? Jusificar.  
b) ¿Cuántos caracteres en total tiene que tener un texto como mínimo para que algún caracter reciba un código de longitud k en una codificación de Huffman (con k>1)? Justificar  
c) Responder a) y b) para códogs de longitud fija. Justificar.

### Consigna

### Tema no visto en este cuatrimestre

## Ejercicio 5

### Consigna

Considerar una tabla hash con direccionamiento abierto, en la cual se marca de forma diferenciada las posiciones que contienen un elemento, aquellas que nunca contuvieron un elemento y aquellas que en algún momento tuvieron un elemento pero fue borrado. Describir los algoritmos de inserción, búsqueda y borrado y analizar sus complejidades asintóticas. Comparar con la versión de hashing en la cual no se puede distinguir los borrados de "vacio".

### Resolución

Si no se pudiera distinguir entre NIL y DELETED, entonces al borrar un elemento quedará su posición vacía (y los elementos que coincidian en el hashing y habían sido insertados más adelante durante el barrido no retomarán esta posición) y al buscarlo puede que devuelva falso al toparse con un NIL, cuando en realidad la clave puede estar más adelante. Por esto, la complejidad promedio ya no sería tan buena y perdería la "gracia" de la tabla hash: tendría todo complejidad lineal